{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq   # 웹페이지 요청 라이브러리\n",
    "\n",
    "url = 'https://quotes.toscrape.com/'\n",
    "quote = rq.get(url)\n",
    "\n",
    "quote.content[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup   # html 형식으로 뽑을 수 있게 잘 바꿔주는 라이브러리\n",
    "\n",
    "quote_html = BeautifulSoup(quote.content, 'html.parser')\n",
    "quote_html.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명언이 존재하는 div 태그를 먼저 뽑음\n",
    "\n",
    "quote_div = quote_html.find_all('div', class_='quote')\n",
    "\n",
    "quote_div[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명언이 존재하는 div 태그 내의 span 태그를 따로 뽑기\n",
    "\n",
    "quote_span = quote_div[0].find_all('span', class_='text')\n",
    "\n",
    "quote_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# span 태그 내의 텍스트 데이터만 추출\n",
    "\n",
    "quote_span[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 과정을 한번에 처리하기\n",
    "\n",
    "quote_div = quote_html.find_all('div', class_='quote')\n",
    "\n",
    "[i.find_all('span', class_='text')[0].text for i in quote_div]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 함수 내에 찾고자 하는 태그를 입력, 클래스명이 존재할 경우 . 이후에 클래스명 입력\n",
    "# 여러 태그를 찾아 내려갈 때는 > 사용\n",
    "quote_text = quote_html.select('div.quote > span.text')\n",
    "\n",
    "quote_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_text_list = [i.text for i in quote_text]\n",
    "\n",
    "quote_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 말한 사람 이름 추출하기\n",
    "quote_author = quote_html.select('div.quote > span > small.author')\n",
    "\n",
    "quote_author_list = [i.text for i in quote_author]\n",
    "quote_author_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 말한 사람 정보 추출하기\n",
    "quote_link = quote_html.select('div.quote > span > a')\n",
    "\n",
    "quote_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quote_link[0]['href'] - 속성 값 정보 추출\n",
    "\n",
    "['https://quotes.toscrape.com' + i['href'] for i in quote_link]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹사이트의 모든 페이지를 크롤링하는 예제\n",
    "\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "text_list = []\n",
    "author_list = []\n",
    "infor_list = []\n",
    "\n",
    "for i in range(1, 100):\n",
    "    url = f'https://quotes.toscrape.com/page/{i}/'\n",
    "    quote = rq.get(url)\n",
    "    quote_html = BeautifulSoup(quote.content, 'html.parser')\n",
    "    \n",
    "    quote_text = quote_html.select('div.quote > span.text')\n",
    "    quote_text_list = [i.text for i in quote_text]\n",
    "    \n",
    "    quote_author = quote_html.select('div.quote > span > small.author')\n",
    "    quote_author_list = [i.text for i in quote_author]\n",
    "    \n",
    "    quote_link = quote_html.select('div.quote > span > a')\n",
    "    quote_link_list = ['https://quotes.toscrape.com' + i['href'] for i in quote_link]\n",
    "    \n",
    "    if len(quote_text_list) > 0:\n",
    "        text_list.extend(quote_text_list)\n",
    "        author_list.extend(quote_author_list)\n",
    "        infor_list.extend(quote_link_list)\n",
    "        time.sleep(1)\n",
    "        \n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "quote_df = pd.DataFrame({'text': text_list, 'author': author_list, 'infor': infor_list})\n",
    "quote_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기사 제목 뽑기 예제\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://finance.naver.com/news/news_list.nhn?mode=LSS2D&section_id=101&section_id2=258'\n",
    "data = rq.get(url)\n",
    "html = BeautifulSoup(data.content, 'html.parser')\n",
    "html_select = html.select('dl > dd.articleSubject > a')\n",
    "\n",
    "html_select[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title 속성에 있는 내용 뽑아내기\n",
    "[i['title'] for i in html_select]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링을 원하는 데이터가 표 형태로 되어있을 경우\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_stock_market_capitalization'\n",
    "tbl = pd.read_html(url)\n",
    "\n",
    "tbl[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국거래소 상장공시시스템에서 POST 요청을 보내 데이터 뽑아내기\n",
    "\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://kind.krx.co.kr/disclosure/todaydisclosure.do'\n",
    "payload = {\n",
    "   'method': 'searchTodayDisclosureSub',\n",
    "   'currentPageSize': '15',\n",
    "   'pageIndex': '1',\n",
    "   'orderMode': '0',\n",
    "   'orderStat':'D',\n",
    "   'forward': 'todaydisclosure_sub',\n",
    "   'chose': 'S',\n",
    "   'todayFlag': 'N',\n",
    "   'selDate': '2025-01-03'\n",
    "}\n",
    "\n",
    "data = rq.post(url, data=payload)       # post request\n",
    "html = BeautifulSoup(data.content, 'html.parser')\n",
    "\n",
    "# print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_unicode = html.prettify()  # BeautifulSoup에서 파싱한 파서 트리를 유니코드 형태로 돌려놓기\n",
    "html_unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = pd.read_html(html.prettify()) # html 문자열로 변환 후 read_html 사용\n",
    "tbl[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
